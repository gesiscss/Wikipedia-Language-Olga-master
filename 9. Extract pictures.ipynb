{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load wikipedia_prof.py\n",
    "__author__ = 'babak'\n",
    "import wikipedia\n",
    "import MySQLdb\n",
    "import re\n",
    "#import pandas as pd\n",
    "#import xlrd\n",
    "from wikitools import wiki, api\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "class professions:\n",
    "    rows_list=[]\n",
    "    job_list=[]\n",
    "    def read_data(self):\n",
    "        # number of rows = 120212\n",
    "        # PsID = []\n",
    "\n",
    "        with open('professions-wikipedia2.csv', 'rb') as f:\n",
    "            reader = csv.reader(f)\n",
    "            self.rows_list = list(reader)\n",
    "\n",
    "        # workbook = xlrd.open_workbook('pantheon.csv')\n",
    "        #\n",
    "        # sheet = workbook.sheet_by_index(0)\n",
    "        # # cell = sheet.cell_value(0,0)\n",
    "        # # print cell\n",
    "        # # rows = sheet.nrows\n",
    "        # self.rows_list = [[sheet.cell_value(row,c) for c in range(sheet.ncols)] for row in range(1,sheet.nrows)]\n",
    "\n",
    "        print len(self.rows_list)\n",
    "        print self.rows_list[1][13]\n",
    "        print (\"xls fetched...\")\n",
    "        self.get_image_link()\n",
    "\n",
    "    def get_image_link(self):\n",
    "        wiki_image_list=[]\n",
    "        filename = 'profession_images.txt'\n",
    "        df = pd.DataFrame(columns=[ 'language_label', 'profession','wikipedia_link', 'image_link'])\n",
    "        for i in range(1,len(self.rows_list)):\n",
    "\n",
    "            print \"row number =\",i\n",
    "            all_links=[]\n",
    "\n",
    "            wikipedia.set_lang('en')\n",
    "            prof = self.rows_list[i][0]\n",
    "            try:\n",
    "                page_title = self.rows_list[i][13].split('/')[4]\n",
    "            except:\n",
    "                continue\n",
    "            print page_title\n",
    "\n",
    "            params = {'action':'query',\n",
    "                'format':'json',\n",
    "                'titles':page_title,\n",
    "                'prop':'langlinks',\n",
    "                'lllimit':'100',\n",
    "                'llurl':'',\n",
    "\n",
    "                'continue':''\n",
    "            }\n",
    "            try:\n",
    "\n",
    "\n",
    "                #---------------------------------- wikitools library ----------------------------------------\n",
    "                site = wiki.Wiki('http://en.wikipedia.org/w/api.php')\n",
    "                req = api.APIRequest(site, params)\n",
    "                res = req.query()\n",
    "                # pprint.pprint(res)\n",
    "                #--------------------------------------------------------------------------------------\n",
    "                #print res\n",
    "                all_links.append(['en',page_title,prof,self.rows_list[i][13]])\n",
    "                lang_list = res['query']['pages'].values()[0]['langlinks']\n",
    "                for lang in lang_list:\n",
    "                    lang_id = lang['lang']\n",
    "                    lang_url = lang['url']\n",
    "                    wiki_name = lang['*']\n",
    "\n",
    "                    all_links.append([lang_id,wiki_name,prof,lang_url])\n",
    "                for data in all_links:\n",
    "                    lang_id = data[0]\n",
    "                    try :\n",
    "\n",
    "                        #print data[1]\n",
    "                        params2 = {'action':'query',\n",
    "                            'format':'json',\n",
    "                            'titles':data[1],\n",
    "                            'generator':'images',\n",
    "                            'gimlimit':10,\n",
    "                            'prop':'imageinfo',\n",
    "                            'iiprop':'url',\n",
    "                            'continue':''\n",
    "                        }\n",
    "\n",
    "                        #---------------------------------- wikitools library ----------------------------------------\n",
    "                        site2 = wiki.Wiki('http://%s.wikipedia.org/w/api.php' %lang_id)\n",
    "                        req = api.APIRequest(site2, params2)\n",
    "                        res = req.query()\n",
    "                        #--------------------------------------------------------------------------------------\n",
    "                        for item in  res['query']['pages'].values():\n",
    "                            #if 'Wiktionary' or 'Ambox' not in item['imageinfo'][0]['url'].split('/')[7]:\n",
    "                                #print item['imageinfo'][0]['url']\n",
    "                            wiki_dict={ 'language_label':data[0], 'profession':data[2],'wikipedia_link':data[3], 'image_link':item['imageinfo'][0]['url']}\n",
    "                            df = df.append(wiki_dict, ignore_index=True)\n",
    "\n",
    "                    except:\n",
    "                        wiki_dict={ 'language_label':data[0], 'profession':data[2],'wikipedia_link':data[3], 'image_link':'-'}\n",
    "                        df = df.append(wiki_dict, ignore_index=True)\n",
    "                        continue\n",
    "\n",
    "            except:\n",
    "                print \"error on row : \" ,i\n",
    "                continue\n",
    "        df.to_csv(filename, sep='\\t', encoding='utf-8')\n",
    "\n",
    "    def search(self):\n",
    "        counter =0\n",
    "        for i in range(len(self.rows_list)):\n",
    "            counter +=1\n",
    "            print counter\n",
    "            prof = self.rows_list[i][0][:-1]\n",
    "            result = wikipedia.search(prof)\n",
    "            print prof, \" : \",result\n",
    "            for item in result:\n",
    "                #print prof\n",
    "                try:\n",
    "                    if prof in item:\n",
    "                        print item\n",
    "                        self.job_list.append(item)\n",
    "                except:\n",
    "                    continue\n",
    "        print len(self.job_list)\n",
    "if __name__ == '__main__':\n",
    "    p = professions()\n",
    "\n",
    "    p.read_data()\n",
    "    #p.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
