{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def load_simple_json(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "words=load_simple_json('de/occupation_all.json')#{masculine:[[],[feminine]]}\n",
    "words_revert={words[i][1]:i for i in words}#feminine:masculine\n",
    "#neutral=load_simple_json('de/neutral_new.json')\n",
    "\n",
    "no_page_m=load_simple_json('de/wiki/m_no_page.json')\n",
    "no_page_f=load_simple_json('de/wiki/f_no_page.json')\n",
    "#no_page_n=load_simple_json('de/wiki/n_no_page.json')\n",
    "page_m=load_simple_json('de/wiki/m_page.json')\n",
    "page_f=load_simple_json('de/wiki/f_page.json')\n",
    "#page_n=load_simple_json('de/wiki/n_page.json')\n",
    "m_page_levenshtein=load_simple_json('de/wiki/m_page_levenshtein.json')\n",
    "#n_page_levenshtein=load_simple_json('de/wiki/n_page_levenshtein.json')\n",
    "\n",
    "\n",
    "page_f_validated=load_simple_json('de/wiki/f_page_validated.json')\n",
    "page_f_ambigious=load_simple_json('de/wiki/f_page_ambigious.json')\n",
    "page_f_other=load_simple_json('de/wiki/f_page_other.json')  \n",
    "    \n",
    "page_m_validated=load_simple_json('de/wiki/m_page_validated.json') \n",
    "page_m_ambigious=load_simple_json('de/wiki/m_page_ambigious.json')\n",
    "page_m_other=load_simple_json('de/wiki/m_page_other.json')\n",
    "\n",
    "#page_n_validated=load_simple_json('de/wiki/n_page_validated.json')\n",
    "#page_n_ambigious=load_simple_json('de/wiki/n_page_ambigious.json')\n",
    "#page_n_other=load_simple_json('de/wiki/n_page_other.json') \n",
    "\n",
    "m_links_to_feminine=load_simple_json('de/wiki/m_links_to_feminine.json')\n",
    "m_links_to_smth=load_simple_json('de/wiki/m_links_to_smth.json')\n",
    "f_links_to_mascuilne=load_simple_json('de/wiki/f_links_to_mascuilne.json')\n",
    "f_links_to_smth=load_simple_json('de/wiki/f_links_to_smth.json')\n",
    "#redirection_n=load_simple_json('de/wiki/n_redirects.json')\n",
    "f_links_to_mascuilne_lev=load_simple_json('de/wiki/f_links_to_mascuilne_lev.json')\n",
    "\n",
    "\n",
    "\n",
    "with open(\"de/googlenumber_new2.json\", 'r') as f:\n",
    "    googlenumber=json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prediction function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "def predict_linear_regr(df,C_val=1e5,multi_class='ovr',n=1):#'multinomial'\n",
    "    X = df.get_values()[:,:n] # we only take the first two features.\n",
    "    Y = df.Wiki\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "    print \"train and test data size:\",X_train.shape, X_test.shape\n",
    "    logreg = linear_model.LogisticRegression(C=C_val,solver='newton-cg',multi_class='multinomial')# lbfgs’ & ‘newton-cg’ solvers\n",
    "    # we create an instance of Neighbours Classifier and fit the data.\n",
    "    logreg_fit=logreg.fit(X_train, y_train)\n",
    "    #print logreg_fit.intercept_\n",
    "    y_pred = logreg_fit.predict(X_test)\n",
    "    print\"{0} / {1} correct ({2})\".format(np.sum(y_test == y_pred), len(y_test),np.sum(y_test == y_pred)/float(len(y_test)))\n",
    "    print \"Last 90 predicted values:\",y_pred[-90:]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple Google hits, predict if wiki page exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and test data size: (3123, 1) (1041, 1)\n",
      "733 / 1041 correct (0.704130643612)\n",
      "Last 90 predicted values: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "#dependent var\n",
    "#(i) has WP article entry with text (real article), #1\n",
    "#(ii) has entry that is a redirect to other gender profession name, #2\n",
    "#(iii) has entry that is a redirect to something else, #3\n",
    "#(iv) has no entry at all #4\n",
    "#use as independent vars /predictors:\n",
    "#(i) total number of google hits, \n",
    "#(ii) relative hits in relation to gender counterpart (i would suggest to just sum up hits for male and female and take the percentage for the target gender), \n",
    "#(iii) chars in profession name (just for control)\n",
    "\n",
    "\n",
    "#male\n",
    "google_rank_male={}\n",
    "for i in words:\n",
    "    if (i in page_m_validated):\n",
    "        google_rank_male[i]=[int(googlenumber[i][0]),1]\n",
    "    elif (i in m_links_to_feminine):\n",
    "        google_rank_male[i]=[int(googlenumber[i][0]),2]\n",
    "    elif (i in m_links_to_smth) :#3\n",
    "        google_rank_male[i]=[int(googlenumber[i][0]),3]\n",
    "    #elif (i in no_page_m):\n",
    "    else:\n",
    "        google_rank_male[i]=[int(googlenumber[i][0]),4]\n",
    "\n",
    "        \n",
    "        \n",
    "len(google_rank_male)\n",
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(google_rank_male,orient='index')\n",
    "df.columns = ['GoogleResults', 'Wiki']\n",
    "res1=predict_linear_regr(df)\n",
    "\n",
    "for i in res1:\n",
    "    if i!=4:\n",
    "        print 'Not equal \"4\": ',i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#use difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and test data size: (3123, 1) (1041, 1)\n",
      "724 / 1041 correct (0.695485110471)\n",
      "Last 90 predicted values: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4]\n",
      "Not equal  \"4\" 34 times\n"
     ]
    }
   ],
   "source": [
    "google_dif={}\n",
    "for i in googlenumber:\n",
    "    google_dif[i]=int(googlenumber[i][0])-int(googlenumber[i][1])\n",
    "\n",
    "#start with male bias\n",
    "google_rank_male={}\n",
    "for i in words:\n",
    "    if (i in page_m):\n",
    "        google_rank_male[i]=[google_dif[i],1]\n",
    "    elif (i in m_links_to_feminine):\n",
    "        google_rank_male[i]=[google_dif[i],2]\n",
    "    elif (i in m_links_to_smth) :#3\n",
    "        google_rank_male[i]=[google_dif[i],3]\n",
    "    elif (i in no_page_m):\n",
    "        google_rank_male[i]=[google_dif[i],4]\n",
    "\n",
    "len(google_rank_male)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(google_rank_male,orient='index')\n",
    "df.columns = ['GoogleResults', 'Wiki']\n",
    "res2=predict_linear_regr(df)\n",
    "n=0\n",
    "for i in res2:\n",
    "    if i!=4:\n",
    "        n+=1\n",
    "print 'Not equal  \"4\" {0} times'.format(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#use percentage\n",
    "##male prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   GoogleResults  Wiki\n",
      "Revisor                                99.346950     1\n",
      "Krankenversicherungskalkulator         70.000000     4\n",
      "Aquariumbauer                          99.820144     4\n",
      "Planungstechniker                      91.769547     4\n",
      "Ozeanograph                            88.412960     3\n",
      "Immobilienbetriebswirt                 83.042394     4\n",
      "Radio- und Fernsehtechniker            98.284128     3\n",
      "Finanzdienstleister                    99.522780     3\n",
      "NC-Anwendungsfachmann                  95.106383     4\n",
      "Bekleidungsteilenäher                  80.555556     4\n",
      "Buchfertigmacher                       91.428571     4\n",
      "Rohrvorrichter                         98.870056     3\n",
      "Familiengesundheitspfleger             65.000000     4\n",
      "Metallformer                           98.953378     4\n",
      "Heilerziehungspflegehelfer             83.843618     3\n",
      "Komparse                               82.323232     1\n",
      "Direktionsbevollmächtigter             82.352941     4\n",
      "Erwachsenenheimleiter                  65.581395     4\n",
      "Leitergerüstbauer                      92.000000     4\n",
      "Versicherungsinspektor                 92.427184     4\n",
      "Genetiker                              93.014569     3\n",
      "Barmeister                             97.110580     1\n",
      "Elektro- und Schutzgasschweißer        95.708155     4\n",
      "Pflanzenschützer                       96.373057     4\n",
      "Keramikermeister                       77.488515     4\n",
      "Onlineredakteur                        66.666667     4\n",
      "Schmuckgoldschmied                    100.000000     4\n",
      "Tibetologe                             66.998578     3\n",
      "Verhaltenstherapeut                    60.162602     3\n",
      "Theaterschneider                       44.253633     4\n",
      "...                                          ...   ...\n",
      "Feinpolierer                           91.484716     1\n",
      "Sicherheitstechniker                   95.298602     3\n",
      "Betonfertigteilbauer                   96.708418     1\n",
      "Serviermeister                         97.890295     4\n",
      "Hauswirtschaftlicher Berater           18.867925     4\n",
      "Glasapparatebläser                     96.078431     4\n",
      "Social-Media-Manager                   99.048612     1\n",
      "Bewegungspädagoge                      17.655786     4\n",
      "Presseneinrichter                      99.833333     4\n",
      "Chefkoch                               99.518691     3\n",
      "Hochbautechniker                       95.135258     4\n",
      "Kühlerklempner                         91.666667     4\n",
      "Elektriker                             99.803048     3\n",
      "Gastronom                              95.522388     3\n",
      "Friedhofsgärtner                       96.735187     3\n",
      "Maler- und Lackiererhelfer             94.405594     4\n",
      "Disponent                              90.909091     1\n",
      "Industrieschmied                       96.226415     4\n",
      "Bohrarbeiter                           72.949816     4\n",
      "Anwendungsberater                      94.226848     4\n",
      "Bergbautechnologe                      82.963901     1\n",
      "Langdrehautomatendreher                85.714286     4\n",
      "Kundendienstleiter                     94.732370     4\n",
      "Torfarbeiter                           98.067633     4\n",
      "Radio- und Fernsehtechnikerhelfer     100.000000     4\n",
      "Holzbearbeitungsmechaniker             96.281909     1\n",
      "Popularmusiker                         88.235294     4\n",
      "Serviceberater                         96.469418     4\n",
      "Praktischer Betriebswirt               84.222474     4\n",
      "Digitaldrucker                         99.830730     4\n",
      "\n",
      "[4164 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "google_dif={}\n",
    "for i in googlenumber:\n",
    "    sum_m_f=float(int(googlenumber[i][0])+int(googlenumber[i][1]))\n",
    "    google_dif[i]=100*float(googlenumber[i][0])/sum_m_f if sum_m_f!=0 else 0\n",
    "\n",
    "#start with male bias\n",
    "google_rank_male={}\n",
    "for i in words:\n",
    "    if (i in page_m):\n",
    "        google_rank_male[i]=[google_dif[i],1]\n",
    "    elif (i in m_links_to_feminine):\n",
    "        google_rank_male[i]=[google_dif[i],2]\n",
    "    elif (i in m_links_to_smth) :#3\n",
    "        google_rank_male[i]=[google_dif[i],3]\n",
    "    elif (i in no_page_m):\n",
    "        google_rank_male[i]=[google_dif[i],4]\n",
    "\n",
    "len(google_rank_male)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(google_rank_male,orient='index')\n",
    "df.columns = ['GoogleResults', 'Wiki']\n",
    "print df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and test data size: (3123, 1) (1041, 1)\n",
      "704 / 1041 correct (0.676272814601)\n",
      "Last 90 predicted values: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "train and test data size: (3123, 1) (1041, 1)\n",
      "682 / 1041 correct (0.655139289145)\n",
      "Last 90 predicted values: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "res3=predict_linear_regr(df)\n",
    "\n",
    "for i in res3:\n",
    "    if i!=4:\n",
    "        print \"Not equal 4: \",i\n",
    "        \n",
    "res3=predict_linear_regr(df,C_val=1)\n",
    "\n",
    "for i in res3:\n",
    "    if i!=4:\n",
    "        print \"Not equal 4: \",i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##female prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "google_dif={}\n",
    "for i in googlenumber:\n",
    "    sum_m_f=float(int(googlenumber[i][0])+int(googlenumber[i][1]))\n",
    "    google_dif[i]=100*float(googlenumber[i][1])/sum_m_f if sum_m_f!=0 else 0\n",
    "\n",
    "#start with male bias\n",
    "google_rank_male={}\n",
    "for i in words:\n",
    "    if (words[i][1] in page_f):\n",
    "        google_rank_male[i]=[google_dif[i],1]\n",
    "    elif (words[i][1] in f_links_to_mascuilne):\n",
    "        google_rank_male[i]=[google_dif[i],2]\n",
    "    elif (words[i][1] in f_links_to_smth) :#3\n",
    "        google_rank_male[i]=[google_dif[i],3]\n",
    "    elif (words[i][1] in no_page_f):\n",
    "        google_rank_male[i]=[google_dif[i],4]\n",
    "\n",
    "len(google_rank_male)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(google_rank_male,orient='index')\n",
    "df.columns = ['GoogleResults', 'Wiki']\n",
    "print df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and test data size: (3123, 1) (1041, 1)\n",
      "974 / 1041 correct (0.935638808838)\n",
      "Last 90 predicted values: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "train and test data size: (3123, 1) (1041, 1)\n",
      "962 / 1041 correct (0.924111431316)\n",
      "Last 90 predicted values: [4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "res4=predict_linear_regr(df)\n",
    "\n",
    "for i in res4:\n",
    "    if i!=4:\n",
    "        print \"Not equal 4: \",i\n",
    "\n",
    "res4=predict_linear_regr(df,multi_class='multinomial')\n",
    "for i in res4:\n",
    "    if i!=4:\n",
    "        print \"Not equal 4: \",i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and test data size: (3123, 3) (1041, 3)\n",
      "734 / 1041 correct (0.705091258405)\n",
      "Last 90 predicted values: [4 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 4 4 4 4 1 4 4 4 1 4 4 4 4 4\n",
      " 4 1 4 1 4 4 4 4 4 4 4 4 1 4 4 4 4 4 1 4 1 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4]\n",
      "Not equal  \"4\" 73 times\n"
     ]
    }
   ],
   "source": [
    "google_dif={}\n",
    "for i in googlenumber:\n",
    "    google_dif[i]=int(googlenumber[i][0])-int(googlenumber[i][1])\n",
    "\n",
    "google_percent={}\n",
    "for i in googlenumber:\n",
    "    sum_m_f=float(int(googlenumber[i][0])+int(googlenumber[i][1]))\n",
    "    google_percent[i]=100*float(googlenumber[i][0])/sum_m_f if sum_m_f!=0 else 0\n",
    "#start with male bias\n",
    "google_rank_male={}\n",
    "for i in words:\n",
    "    if (i in page_m):\n",
    "        google_rank_male[i]=[int(googlenumber[i][0]),google_dif[i],google_percent[i],1]\n",
    "    elif (i in m_links_to_feminine):\n",
    "        google_rank_male[i]=[int(googlenumber[i][0]),google_dif[i],google_percent[i],2]\n",
    "    elif (i in m_links_to_smth) :#3\n",
    "        google_rank_male[i]=[int(googlenumber[i][0]),google_dif[i],google_percent[i],3]\n",
    "    elif (i in no_page_m):\n",
    "        google_rank_male[i]=[int(googlenumber[i][0]),google_dif[i],google_percent[i],4]\n",
    "\n",
    "len(google_rank_male)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(google_rank_male,orient='index')\n",
    "df.columns = ['GoogleResults','GoogleDif', 'GooglePercent','Wiki']\n",
    "res2=predict_linear_regr(df,n=3)\n",
    "n=0\n",
    "for i in res2:\n",
    "    if i!=4:\n",
    "        n+=1\n",
    "print 'Not equal  \"4\" {0} times'.format(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Trash & old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#count: masculine exist AND (no feminine OR feminine label redirects to masculine label) => male bias (Rank 1)\n",
    "#count: feminine exist AND (no masculine OR masculine label redirects to feminine label)  => female bias (Rank 3)\n",
    "#count: masculine exist AND feminine exist => balanced (Rank 2)\n",
    "\n",
    "#start with male bias\n",
    "male_bias_labels=[]\n",
    "female_bias_labels=[]\n",
    "no_bias=[]\n",
    "wiki_bias_rank={}\n",
    "for i in words:\n",
    "    if ((i in page_m)&(words[i][1] not in page_f))|((i in page_m)&(i in m_links_to_feminine)):\n",
    "        male_bias_labels.append(i)\n",
    "        wiki_bias_rank[i]=1\n",
    "    elif ((words[i][1] in page_f)&(i not in page_m))|((words[i][1] in page_f)&(i in f_links_to_mascuilne)):\n",
    "        female_bias_labels.append(i)\n",
    "        wiki_bias_rank[i]=3\n",
    "        #print i\n",
    "    elif (i in page_m)&(words[i][1] in page_f):\n",
    "        no_bias.append(i)\n",
    "        wiki_bias_rank[i]=2\n",
    "        #print i\n",
    "    else:\n",
    "        wiki_bias_rank[i]=0\n",
    "print \"Male bias:\",len(male_bias_labels),\", Female bias:\",len(female_bias_labels),\", No bias:\",len(no_bias)\n",
    "\n",
    "with open(\"de/googlenumber_new2.json\", 'r') as f:\n",
    "    googlenumber=json.load(f)\n",
    "google_rank_male={}\n",
    "for i in words:\n",
    "    if wiki_bias_rank.has_key(i):\n",
    "        google_rank_male[i]=[int(googlenumber[i][0]),wiki_bias_rank[i]]      \n",
    "        \n",
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(google_rank_male,orient='index')\n",
    "df.columns = ['GoogleResults', 'Wiki']\n",
    "predict_linear_regr(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "#google Results\n",
    "#difference would be our Goosle Runking\n",
    "with open(\"de/googlenumber_new.json\", 'r') as f:\n",
    "    googlenumber=json.load(f)\n",
    "google_dif={}\n",
    "for i in googlenumber:\n",
    "    google_dif[i]=int(googlenumber[i][0])-int(googlenumber[i][1])\n",
    "    \n",
    "#Rank these values\n",
    "from scipy import stats\n",
    "google_rank=stats.rankdata(google_dif.values())\n",
    "google_rank_labels=google_dif.keys()\n",
    "google_rank_dict={}\n",
    "print google_dif.keys().index(u'Ozeanograph'),google_rank_labels.index(u'Ozeanograph')\n",
    "for i in google_dif.keys():\n",
    "    if wiki_bias_rank.has_key(i):\n",
    "        google_rank_dict[i]=[google_rank[google_dif.keys().index(i)],wiki_bias_rank[i]]\n",
    "    else:\n",
    "        google_rank_dict[i]=[google_rank[google_dif.keys().index(i)],None]\n",
    "print len(google_rank_labels),len(google_rank_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Prediction example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code source: Gaël Varoquaux\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, datasets\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "Y = iris.target\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "logreg.fit(X, Y)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot also the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 2) (38, 2)\n",
      "[ 96.61635458   9.13595029 -15.66607786]\n",
      "28 / 38 correct\n",
      "[1 2 0 1 0 2 0 2 0 1 1 1 0 1 2 0 2 2 0 0 1 2 2 0 0 1 2 1 0 2 2 0 2 0 1 0 0\n",
      " 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "Y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "print X_train.shape, X_test.shape\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "# we create an instance of Neighbours Classifier and fit the data.\n",
    "logreg_fit=logreg.fit(X_train, y_train)\n",
    "print logreg_fit.intercept_\n",
    "y_pred = logreg_fit.predict(X_test)\n",
    "print(\"{0} / {1} correct\".format(np.sum(y_test == y_pred), len(y_test)))\n",
    "print y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
